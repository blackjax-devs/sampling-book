{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0082b59d",
   "metadata": {},
   "source": [
    "# Bayesian Logistic Regression\n",
    "\n",
    "In this notebook we demonstrate the use of the random walk Rosenbluth-Metropolis-Hasting algorithm on a simple logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53dea7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import jax.random as random\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_biclusters\n",
    "\n",
    "import blackjax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e31faa5",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "plt.rcParams[\"axes.spines.right\"] = False\n",
    "plt.rcParams[\"axes.spines.top\"] = False\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e87d83",
   "metadata": {},
   "source": [
    "## The Data\n",
    "\n",
    "We create two clusters of points using [scikit-learn's `make_bicluster` function](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_biclusters.html?highlight=bicluster%20data#sklearn.datasets.make_biclusters)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3dc0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_points = 50\n",
    "X, rows, cols = make_biclusters(\n",
    "    (num_points, 2), 2, noise=0.6, random_state=314, minval=-3, maxval=3\n",
    ")\n",
    "y = rows[0] * 1.0  # y[i] = whether point i belongs to cluster 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15d722d",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "colors = [\"tab:red\" if el else \"tab:blue\" for el in rows[0]]\n",
    "plt.scatter(*X.T, edgecolors=colors, c=\"none\")\n",
    "plt.xlabel(r\"$X_0$\")\n",
    "plt.ylabel(r\"$X_1$\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05716ab4",
   "metadata": {},
   "source": [
    "## The Model\n",
    "\n",
    "We use a simple logistic regression model to infer to which cluster each of the points belongs. We note $y$ a binary variable that indicates whether a point belongs to the first cluster :\n",
    "\n",
    "$$\n",
    "y \\sim \\operatorname{Bernoulli}(p)\n",
    "$$\n",
    "\n",
    "The probability $p$ to belong to the first cluster commes from a logistic regression:\n",
    "\n",
    "$$\n",
    "p = \\operatorname{logistic}(\\Phi\\,\\boldsymbol{w})\n",
    "$$\n",
    "\n",
    "where $w$ is a vector of weights whose priors are a normal prior centered on 0:\n",
    "\n",
    "$$\n",
    "\\boldsymbol{w} \\sim \\operatorname{Normal}(0, \\sigma)\n",
    "$$\n",
    "\n",
    "And $\\Phi$ is the matrix that contains the data, so each row $\\Phi_{i,:}$ is the vector $\\left[1, X_0^i, X_1^i\\right]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b35d4f",
   "metadata": {
    "tags": [
     "hide-stderr"
    ]
   },
   "outputs": [],
   "source": [
    "Phi = jnp.c_[jnp.ones(num_points)[:, None], X]\n",
    "N, M = Phi.shape\n",
    "\n",
    "\n",
    "def sigmoid(z):\n",
    "    return jnp.exp(z) / (1 + jnp.exp(z))\n",
    "\n",
    "\n",
    "def log_sigmoid(z):\n",
    "    return z - jnp.log(1 + jnp.exp(z))\n",
    "\n",
    "\n",
    "def logdensity_fn(w, alpha=1.0):\n",
    "    \"\"\"The log-probability density function of the posterior distribution of the model.\"\"\"\n",
    "    log_an = log_sigmoid(Phi @ w)\n",
    "    an = Phi @ w\n",
    "    log_likelihood_term = y * log_an + (1 - y) * jnp.log(1 - sigmoid(an))\n",
    "    prior_term = alpha * w @ w / 2\n",
    "\n",
    "    return -prior_term + log_likelihood_term.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf3c6a27",
   "metadata": {},
   "source": [
    "## Posterior Sampling\n",
    "\n",
    "We use `blackjax`'s Random Walk RMH kernel to sample from the posterior distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da1c880",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng_key = random.PRNGKey(314)\n",
    "\n",
    "w0 = random.multivariate_normal(rng_key, 0.1 + jnp.zeros(M), jnp.eye(M))\n",
    "\n",
    "rmh = blackjax.rmh(logdensity_fn, sigma=jnp.ones(M) * 0.7)\n",
    "initial_state = rmh.init(w0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8780585",
   "metadata": {},
   "source": [
    "Since `blackjax` does not provide an inference loop we need to implement one ourselves:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004e760f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_loop(rng_key, kernel, initial_state, num_samples):\n",
    "    @jax.jit\n",
    "    def one_step(state, rng_key):\n",
    "        state, _ = kernel(rng_key, state)\n",
    "        return state, state\n",
    "\n",
    "    keys = jax.random.split(rng_key, num_samples)\n",
    "    _, states = jax.lax.scan(one_step, initial_state, keys)\n",
    "\n",
    "    return states"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3e3f4c",
   "metadata": {},
   "source": [
    "We can now run the inference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7416024",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, rng_key = random.split(rng_key)\n",
    "states = inference_loop(rng_key, rmh.step, initial_state, 5_000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54847637",
   "metadata": {},
   "source": [
    "And display the trace:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feac7bec",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "burnin = 300\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(12, 2))\n",
    "for i, axi in enumerate(ax):\n",
    "    axi.plot(states.position[:, i])\n",
    "    axi.set_title(f\"$w_{i}$\")\n",
    "    axi.axvline(x=burnin, c=\"tab:red\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45eaa2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "burnin = 300\n",
    "chains = states.position[burnin:, :]\n",
    "nsamp, _ = chains.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b87c943c",
   "metadata": {},
   "source": [
    "### Predictive Distribution\n",
    "\n",
    "Having infered the posterior distribution of the regression's coefficients we can compute the probability to belong to the first cluster at each position $(X_0, X_1)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c858364",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a meshgrid\n",
    "xmin, ymin = X.min(axis=0) - 0.1\n",
    "xmax, ymax = X.max(axis=0) + 0.1\n",
    "step = 0.1\n",
    "Xspace = jnp.mgrid[xmin:xmax:step, ymin:ymax:step]\n",
    "_, nx, ny = Xspace.shape\n",
    "\n",
    "# Compute the average probability to belong to the first cluster at each point on the meshgrid\n",
    "Phispace = jnp.concatenate([jnp.ones((1, nx, ny)), Xspace])\n",
    "Z_mcmc = sigmoid(jnp.einsum(\"mij,sm->sij\", Phispace, chains))\n",
    "Z_mcmc = Z_mcmc.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7bf718",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "plt.contourf(*Xspace, Z_mcmc)\n",
    "plt.scatter(*X.T, c=colors)\n",
    "plt.xlabel(r\"$X_0$\")\n",
    "plt.ylabel(r\"$X_1$\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "file_format": "mystnb",
  "jupytext": {
   "text_representation": {
    "extension": ".md",
    "format_name": "myst",
    "format_version": 0.13,
    "jupytext_version": "1.14.1"
   }
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "mystnb": {
   "execution_timeout": 200
  },
  "source_map": [
   15,
   21,
   31,
   37,
   43,
   51,
   59,
   83,
   106,
   112,
   119,
   123,
   134,
   138,
   141,
   145,
   158,
   162,
   168,
   182
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}